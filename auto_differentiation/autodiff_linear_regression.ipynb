{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing necessay libraries"
      ],
      "metadata": {
        "id": "R1LZoKmfggsR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "naPuVoqo4f7l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function for computational graph plotting"
      ],
      "metadata": {
        "id": "7feKwhkKd3-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from graphviz import Digraph\n",
        "\n",
        "def trace(root):\n",
        "\n",
        "    nodes, edges = set(), set()\n",
        "    def build(v):\n",
        "        if v not in nodes:\n",
        "            nodes.add(v)\n",
        "            for child in v._prev:\n",
        "                edges.add((child, v))\n",
        "                build(child)\n",
        "    build(root)\n",
        "    return nodes, edges\n",
        "\n",
        "def draw_dot(root):\n",
        "    dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'})\n",
        "\n",
        "    nodes, edges = trace(root)\n",
        "    for n in nodes:\n",
        "        uid = str(id(n))\n",
        "\n",
        "        dot.node(name = uid, label=\"{ %s | shape %s | grad %s}\" % (n.label, str(n.tensor.shape), str(n.grad.shape)), shape='record')\n",
        "\n",
        "        if n._op:\n",
        "            dot.node(name = uid + n._op, label=n._op)\n",
        "            dot.edge(uid + n._op, uid)\n",
        "\n",
        "    for n1, n2 in edges:\n",
        "        dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n",
        "\n",
        "    return dot"
      ],
      "metadata": {
        "id": "ltQszuvtd7s1"
      },
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('cleaned_house_data')"
      ],
      "metadata": {
        "id": "Is-Cu1q441Vx"
      },
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "7LX4di_G48WV",
        "outputId": "63389614-ee14-4369-a35c-f12191a47996"
      },
      "execution_count": 322,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   bedrooms  bathrooms  stories  parking  furnishingstatus  log_price  \\\n",
              "0         4          2        3        2                 2  16.403275   \n",
              "1         4          4        4        3                 2  16.321037   \n",
              "2         3          2        2        2                 1  16.321037   \n",
              "3         4          2        2        3                 2  16.318174   \n",
              "4         4          1        2        2                 2  16.250000   \n",
              "\n",
              "   log_area  area_bedrooms  area_bathrooms  bed_bath  amenities_count  \\\n",
              "0  8.911934      35.647736       17.823868         8                3   \n",
              "1  9.100526      36.402103       36.402103        16                2   \n",
              "2  9.206332      27.618997       18.412664         6                3   \n",
              "3  8.922658      35.690632       17.845316         8                4   \n",
              "4  8.911934      35.647736        8.911934         4                4   \n",
              "\n",
              "   total_rooms  \n",
              "0            6  \n",
              "1            8  \n",
              "2            5  \n",
              "3            6  \n",
              "4            5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e849d75c-051a-4062-b568-aee3fb4a2c1c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>stories</th>\n",
              "      <th>parking</th>\n",
              "      <th>furnishingstatus</th>\n",
              "      <th>log_price</th>\n",
              "      <th>log_area</th>\n",
              "      <th>area_bedrooms</th>\n",
              "      <th>area_bathrooms</th>\n",
              "      <th>bed_bath</th>\n",
              "      <th>amenities_count</th>\n",
              "      <th>total_rooms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>16.403275</td>\n",
              "      <td>8.911934</td>\n",
              "      <td>35.647736</td>\n",
              "      <td>17.823868</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>16.321037</td>\n",
              "      <td>9.100526</td>\n",
              "      <td>36.402103</td>\n",
              "      <td>36.402103</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>16.321037</td>\n",
              "      <td>9.206332</td>\n",
              "      <td>27.618997</td>\n",
              "      <td>18.412664</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>16.318174</td>\n",
              "      <td>8.922658</td>\n",
              "      <td>35.690632</td>\n",
              "      <td>17.845316</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>16.250000</td>\n",
              "      <td>8.911934</td>\n",
              "      <td>35.647736</td>\n",
              "      <td>8.911934</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e849d75c-051a-4062-b568-aee3fb4a2c1c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e849d75c-051a-4062-b568-aee3fb4a2c1c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e849d75c-051a-4062-b568-aee3fb4a2c1c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a9374d15-bd62-4606-909c-85ad1935968d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a9374d15-bd62-4606-909c-85ad1935968d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a9374d15-bd62-4606-909c-85ad1935968d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 545,\n  \"fields\": [\n    {\n      \"column\": \"bedrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bathrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4,\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stories\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"parking\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"furnishingstatus\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"log_price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3721652305128729,\n        \"min\": 14.375126,\n        \"max\": 16.403275,\n        \"num_unique_values\": 219,\n        \"samples\": [\n          15.143381,\n          15.480383,\n          14.414347\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"log_area\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.39828339773857807,\n        \"min\": 7.4085307,\n        \"max\": 9.692766,\n        \"num_unique_values\": 284,\n        \"samples\": [\n          8.699514,\n          7.8950634,\n          8.5867195\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"area_bedrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.535150269444771,\n        \"min\": 8.146129608154297,\n        \"max\": 50.19822120666504,\n        \"num_unique_values\": 373,\n        \"samples\": [\n          17.999238967895508,\n          26.760766983032227,\n          27.143463134765625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"area_bathrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.453836002656149,\n        \"min\": 7.408530712127685,\n        \"max\": 36.402103424072266,\n        \"num_unique_values\": 340,\n        \"samples\": [\n          9.468387603759766,\n          8.716044425964355,\n          8.98469352722168\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bed_bath\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 16,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          2,\n          5,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"amenities_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_rooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2,\n        \"max\": 8,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          6,\n          8,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 322
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "bYKfk6K549Ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a415d0c-51a7-4151-ef98-3021f8c285d5"
      },
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bedrooms', 'bathrooms', 'stories', 'parking', 'furnishingstatus',\n",
              "       'log_price', 'log_area', 'area_bedrooms', 'area_bathrooms', 'bed_bath',\n",
              "       'amenities_count', 'total_rooms'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 323
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns = ['log_price'])\n",
        "y = df['log_price']"
      ],
      "metadata": {
        "id": "hvMQRI3g5IrZ"
      },
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6WOK9Ju5JCj",
        "outputId": "f4fdec59-aa9b-40e5-8f17-37756857579f"
      },
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((545, 11), (545,))"
            ]
          },
          "metadata": {},
          "execution_count": 325
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(X))\n",
        "test_size = len(X) - train_size\n",
        "\n",
        "X_train = X[:train_size]\n",
        "y_train = y[:train_size]\n",
        "X_test = X[train_size:]\n",
        "y_test = y[train_size:]"
      ],
      "metadata": {
        "id": "nuiq7SXV5LYe"
      },
      "execution_count": 326,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.tensor(X_train.to_numpy(), dtype = torch.float32)\n",
        "y_train = torch.tensor(y_train.to_numpy(), dtype = torch.float32)\n",
        "y_train = y_train.view(-1, 1)\n",
        "\n",
        "X_test = torch.tensor(X_test.to_numpy(), dtype = torch.float32)\n",
        "y_test = torch.tensor(y_test.to_numpy(), dtype = torch.float32)\n",
        "y_test = y_test.view(-1, 1)\n",
        "\n",
        "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwMzAwAa6w70",
        "outputId": "6311b248-50e6-435b-b3e7-dee6a651b88b"
      },
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([436, 11]),\n",
              " torch.Size([436, 1]),\n",
              " torch.Size([109, 11]),\n",
              " torch.Size([109, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 327
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for dim_x, dim_y in zip(shape_self, shape_other):\n",
        "#     if dim_x != dim_y and dim_x != 1 and dim_y != 1:\n",
        "#         raise ValueError(\"Tensors are not broadcastable\")\n",
        "\n",
        "# self_new_shape = [max(dim_x, dim_y) for dim_x, dim_y in zip(shape_self, shape_other)]\n",
        "# other_new_shape = [max(dim_x, dim_y) for dim_x, dim_y in zip(shape_self, shape_other)]\n",
        "\n",
        "# self.tensor = self.tensor.broadcast_to(tuple(reversed(self_new_shape)))\n",
        "# other.tensor = other.tensor.broadcast_to(tuple(reversed(other_new_shape)))"
      ],
      "metadata": {
        "id": "vXzNAnQ8laGr"
      },
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manually created `TensorValue` class"
      ],
      "metadata": {
        "id": "ltIelKOklurS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.randn(2, 5, 7)\n",
        "print(y.numel())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZr3hIrHiXii",
        "outputId": "e1c1298a-f0f3-4a33-ccdd-760ff50a6cc8"
      },
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With PyTorch's implicit broadcasting"
      ],
      "metadata": {
        "id": "wW-JXx2BUj3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TensorValue:\n",
        "    def __init__(self, tensor, label=None, grad=None, _prev=(), _op=None):\n",
        "        \"\"\"\n",
        "            label\n",
        "            tensor\n",
        "            grad\n",
        "            _prev\n",
        "            _op\n",
        "            _backward\n",
        "            shape\n",
        "            ndim\n",
        "        \"\"\"\n",
        "        self.label = label\n",
        "        self.tensor = tensor if isinstance(tensor, torch.Tensor) else torch.tensor(tensor, dtype=torch.float32)\n",
        "        self.grad = torch.zeros_like(self.tensor) if grad is None else grad\n",
        "        self._prev = set(_prev)\n",
        "        self._op = _op\n",
        "        self._backward = None\n",
        "        self.shape = self.tensor.shape\n",
        "        self.ndim = self.tensor.ndim\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"TensorValue(tensor={self.tensor}, grad={self.grad})\"\n",
        "\n",
        "    # To check shape mismatch and apply DEBROADCASTING\n",
        "    def _match_shape(self, grad, target_shape):\n",
        "        while len(grad.shape) > len(target_shape):\n",
        "            grad = grad.sum(dim=0)\n",
        "        for i, (g_dim, t_dim) in enumerate(zip(grad.shape, target_shape)):\n",
        "            if g_dim != t_dim:\n",
        "                grad = grad.sum(dim=i, keepdim=True)\n",
        "        return grad\n",
        "\n",
        "    #----------------------------------------------------\n",
        "    # Add\n",
        "    #----------------------------------------------------\n",
        "    def __add__(self, other):\n",
        "        output = TensorValue(self.tensor + other.tensor, _prev=(self, other), _op='+')\n",
        "\n",
        "        def backward():\n",
        "            self.grad += self._match_shape(output.grad, self.shape)\n",
        "            other.grad += self._match_shape(output.grad, other.shape)\n",
        "\n",
        "        output._backward = backward\n",
        "        return output\n",
        "\n",
        "   #----------------------------------------------------\n",
        "   # Subtract\n",
        "   #----------------------------------------------------\n",
        "    def __sub__(self, other):\n",
        "        output = TensorValue(self.tensor - other.tensor, _prev=(self, other), _op='-')\n",
        "\n",
        "        def backward():\n",
        "            self.grad += self._match_shape(output.grad, self.shape)\n",
        "            other.grad += -self._match_shape(output.grad, other.shape)\n",
        "\n",
        "        output._backward = backward\n",
        "        return output\n",
        "\n",
        "    #----------------------------------------------------\n",
        "    # Multiply\n",
        "    #----------------------------------------------------\n",
        "    def __mul__(self, other):\n",
        "        output = TensorValue(self.tensor * other.tensor, _prev=(self, other), _op='*')\n",
        "\n",
        "        def backward():\n",
        "            self.grad += self._match_shape(other.tensor * output.grad, self.shape)\n",
        "            other.grad += self._match_shape(self.tensor * output.grad, other.shape)\n",
        "\n",
        "        output._backward = backward\n",
        "        return output\n",
        "\n",
        "   #----------------------------------------------------\n",
        "   # Right multiplication\n",
        "   #----------------------------------------------------\n",
        "    def __rmul__(self, other):\n",
        "        if isinstance(other, (int, float)):\n",
        "            output = TensorValue(self.tensor * other, _prev=(self,), _op='*')\n",
        "            def backward():\n",
        "                self.grad += other * output.grad\n",
        "            output._backward = backward\n",
        "            return output\n",
        "        return self * other\n",
        "\n",
        "   #----------------------------------------------------\n",
        "   # Matrix Multiplication\n",
        "   #----------------------------------------------------\n",
        "    def __matmul__(self, other):\n",
        "        output = TensorValue(self.tensor @ other.tensor, _prev=(self, other), _op='@')\n",
        "\n",
        "        def backward():\n",
        "            self.grad += output.grad @ other.tensor.T\n",
        "            other.grad += self.tensor.T @ output.grad\n",
        "\n",
        "        output._backward = backward\n",
        "        return output\n",
        "\n",
        "    #----------------------------------------------------\n",
        "    # Power\n",
        "    #----------------------------------------------------\n",
        "    def __pow__(self, other):\n",
        "        output = TensorValue(self.tensor ** other, _prev=(self,), _op='**')\n",
        "\n",
        "        def backward():\n",
        "            self.grad += (other * self.tensor ** (other - 1)) * output.grad\n",
        "\n",
        "        output._backward = backward\n",
        "        return output\n",
        "\n",
        "    #----------------------------------------------------\n",
        "    # Mean\n",
        "    #----------------------------------------------------\n",
        "    def mean(self):\n",
        "        output = TensorValue(self.tensor.mean(), _prev=(self,), _op='mean')\n",
        "\n",
        "        def backward():\n",
        "            self.grad += (torch.ones_like(self.tensor) / self.tensor.numel()) * output.grad\n",
        "\n",
        "        output._backward = backward\n",
        "        return output\n",
        "\n",
        "    #----------------------------------------------------\n",
        "    # Topological Sort\n",
        "    #----------------------------------------------------\n",
        "    def backward(self):\n",
        "        topo = []\n",
        "        visited = set()\n",
        "\n",
        "        def build_topo(v):\n",
        "            if v not in visited:\n",
        "                visited.add(v)\n",
        "                for child in v._prev:\n",
        "                    build_topo(child)\n",
        "                topo.append(v)\n",
        "\n",
        "        build_topo(self)\n",
        "\n",
        "        self.grad = torch.ones_like(self.tensor)\n",
        "        for node in reversed(topo):\n",
        "            node._backward()"
      ],
      "metadata": {
        "id": "d4piKODSLzp0"
      },
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With Explicit Broadcasting"
      ],
      "metadata": {
        "id": "Ht-OvAL5OUYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (1,) * (len(shape2) - len(shape1)) + shape1\n",
        "a = torch.randn((4,3))\n",
        "print(a.shape)\n",
        "(1,) * (3 - 2) + a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpOphOUDXQkw",
        "outputId": "a63778e2-f6df-444c-ef35-a33fee983526"
      },
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 4, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 331
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If grad has more dimensions than self, it means some singleton dimensions (size 1) were missing during the forward pass.\n",
        "So, sum over the extra dimensions one by one (starting from the leftmost dimensions) until the number of dimensions match.\n",
        "dim=0 because the extra dimensions are usually leading dimensions (leftmost) when broadcasting."
      ],
      "metadata": {
        "id": "zP-gCH61Y-Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def broadcast_shape(shape1, shape2):\n",
        "  # Padding the shorter shape with 1s on the left\n",
        "  if len(shape1) < len(shape2):\n",
        "      shape1 = (1,) * (len(shape2) - len(shape1)) + shape1\n",
        "  elif len(shape2) < len(shape1):\n",
        "      shape2 = (1,) * (len(shape1) - len(shape2)) + shape2\n",
        "\n",
        "  result = []\n",
        "\n",
        "  for s1, s2 in zip(shape1, shape2):\n",
        "    if s1 == 1:\n",
        "        result.append(s2)\n",
        "    elif s2 == 1:\n",
        "        result.append(s1)\n",
        "    elif s1 == s2:\n",
        "        result.append(s1)\n",
        "    else:\n",
        "        raise ValueError(\"Shapes are not broadcastable\")\n",
        "\n",
        "  return tuple(result)"
      ],
      "metadata": {
        "id": "pBAR_0CUcfei"
      },
      "execution_count": 332,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TensorValue:\n",
        "    \"\"\"\n",
        "            label\n",
        "            tensor\n",
        "            grad\n",
        "            _prev\n",
        "            _op\n",
        "            _backward\n",
        "            shape\n",
        "            ndim\n",
        "    \"\"\"\n",
        "    def __init__(self, tensor, label=None, grad=None, _prev=(), _op=None):\n",
        "        self.label = label\n",
        "        self.tensor = tensor if isinstance(tensor, torch.Tensor) else torch.tensor(tensor, dtype=torch.float32)\n",
        "        self.grad = torch.zeros_like(self.tensor) if grad is None else grad\n",
        "        self._prev = set(_prev)\n",
        "        self._op = _op\n",
        "        self._backward = lambda: None\n",
        "        self.shape = self.tensor.shape\n",
        "        self.ndim = self.tensor.ndim\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"TensorValue(tensor={self.tensor}, grad={self.grad})\"\n",
        "\n",
        "    def _broadcast_tensors(self, other):\n",
        "        # Above function call\n",
        "        out_shape = broadcast_shape(self.shape, other.shape)\n",
        "\n",
        "        a_tensor = self.tensor.expand(out_shape)\n",
        "        b_tensor = other.tensor.expand(out_shape)\n",
        "\n",
        "        # Marking broadcasting operation as a node in computational graph\n",
        "        a = TensorValue(a_tensor, _prev=(self,), _op='broadcast')\n",
        "        a.label = self.label\n",
        "        b = TensorValue(b_tensor, _prev=(other,), _op='broadcast')\n",
        "        b.label = other.label\n",
        "\n",
        "        def _backward_a():\n",
        "            grad = a.grad\n",
        "            while grad.ndim > len(self.shape):\n",
        "                grad = grad.sum(dim=0)\n",
        "            # Grad (1,2,3) and Tensor (1,1,4)\n",
        "              # 1st iter => 1=1\n",
        "              # 2nd iter => 2 != 1 => .sum happens at dim = 1 and so on.....\n",
        "            for i, (g_dim, t_dim) in enumerate(zip(grad.shape, self.shape)):\n",
        "                if t_dim == 1 and g_dim != 1:\n",
        "                    grad = grad.sum(dim=i, keepdim=True)\n",
        "            self.grad += grad\n",
        "\n",
        "        def _backward_b():\n",
        "            grad = b.grad\n",
        "            while grad.ndim > len(other.shape):\n",
        "                grad = grad.sum(dim=0)\n",
        "            for i, (g_dim, t_dim) in enumerate(zip(grad.shape, other.shape)):\n",
        "                if t_dim == 1 and g_dim != 1:\n",
        "                    grad = grad.sum(dim=i, keepdim=True)\n",
        "            other.grad += grad\n",
        "\n",
        "        a._backward = _backward_a\n",
        "        b._backward = _backward_b\n",
        "\n",
        "        return a, b\n",
        "\n",
        "\n",
        "    #----------------------------------------------------\n",
        "    # Add\n",
        "    #----------------------------------------------------\n",
        "    def __add__(self, other):\n",
        "        a, b = self._broadcast_tensors(other)\n",
        "        output = TensorValue(a.tensor + b.tensor, _prev=(a, b), _op='+')\n",
        "\n",
        "        def backward():\n",
        "            a.grad += output.grad\n",
        "            b.grad += output.grad\n",
        "\n",
        "        output._backward = backward\n",
        "        return output\n",
        "\n",
        "    #----------------------------------------------------\n",
        "    # Subtract\n",
        "    #----------------------------------------------------\n",
        "    def __sub__(self, other):\n",
        "        a, b = self._broadcast_tensors(other)\n",
        "        output = TensorValue(a.tensor - b.tensor, _prev=(a, b), _op='-')\n",
        "\n",
        "        def backward():\n",
        "            a.grad += output.grad\n",
        "            b.grad += -output.grad\n",
        "\n",
        "        output._backward = backward\n",
        "        return output\n",
        "\n",
        "    #----------------------------------------------------\n",
        "    # Multiply\n",
        "    #----------------------------------------------------\n",
        "    def __mul__(self, other):\n",
        "        a, b = self._broadcast_tensors(other)\n",
        "        output = TensorValue(a.tensor * b.tensor, _prev=(a, b), _op='*')\n",
        "\n",
        "        def backward():\n",
        "            a.grad += b.tensor * output.grad\n",
        "            b.grad += a.tensor * output.grad\n",
        "\n",
        "        output._backward = backward\n",
        "        return output\n",
        "\n",
        "    #----------------------------------------------------\n",
        "    # Right multiplication\n",
        "    #----------------------------------------------------\n",
        "    def __rmul__(self, other):\n",
        "        if isinstance(other, (int, float)):\n",
        "            output = TensorValue(self.tensor * other, _prev=(self,), _op='*')\n",
        "            def backward():\n",
        "                self.grad += other * output.grad\n",
        "            output._backward = backward\n",
        "            return output\n",
        "        return self * other\n",
        "\n",
        "    #----------------------------------------------------\n",
        "    # Matrix Multiplication\n",
        "    #----------------------------------------------------\n",
        "    def __matmul__(self, other):\n",
        "        other = other if isinstance(other, TensorValue) else TensorValue(other)\n",
        "        output = TensorValue(self.tensor @ other.tensor, _prev=(self, other), _op='@')\n",
        "\n",
        "        def backward():\n",
        "            self.grad += output.grad @ other.tensor.T\n",
        "            other.grad += self.tensor.T @ output.grad\n",
        "\n",
        "        output._backward = backward\n",
        "        return output\n",
        "\n",
        "    #----------------------------------------------------\n",
        "    # Power\n",
        "    #----------------------------------------------------\n",
        "    def __pow__(self, other):\n",
        "        assert isinstance(other, (int, float)), \"Only supports int/float powers\"\n",
        "        output = TensorValue(self.tensor ** other, _prev=(self,), _op='**')\n",
        "\n",
        "        def backward():\n",
        "            self.grad += (other * self.tensor ** (other - 1)) * output.grad\n",
        "\n",
        "        output._backward = backward\n",
        "        return output\n",
        "\n",
        "    #----------------------------------------------------\n",
        "    # Mean\n",
        "    #----------------------------------------------------\n",
        "    def mean(self):\n",
        "        output = TensorValue(self.tensor.mean(), _prev=(self,), _op='mean')\n",
        "\n",
        "        def backward():\n",
        "            self.grad += (torch.ones_like(self.tensor) / self.tensor.numel()) * output.grad\n",
        "\n",
        "        output._backward = backward\n",
        "        return output\n",
        "\n",
        "    #----------------------------------------------------\n",
        "    # Topological Sort\n",
        "    #----------------------------------------------------\n",
        "    def backward(self):\n",
        "        topo = []\n",
        "        visited = set()\n",
        "\n",
        "        def build_topo(v):\n",
        "            if v not in visited:\n",
        "                visited.add(v)\n",
        "                for child in v._prev:\n",
        "                    build_topo(child)\n",
        "                topo.append(v)\n",
        "\n",
        "        build_topo(self)\n",
        "\n",
        "        self.grad = torch.ones_like(self.tensor)\n",
        "        for node in reversed(topo):\n",
        "            node._backward()\n"
      ],
      "metadata": {
        "id": "vgDwTSMfUzIF"
      },
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is all implemented using the PyTorch's defaults, jsut done to verify if the auto differentiation of the TensorValue class works later below or not"
      ],
      "metadata": {
        "id": "FzYXWLTakcda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.randn((11,1), dtype = torch.float32, requires_grad = True) * 0.01\n",
        "b = torch.tensor([1.], requires_grad = True)\n",
        "\n",
        "epochs = 1\n",
        "lr = 0.001\n",
        "\n",
        "for i in range(epochs):\n",
        "  Z = X_train @ W + b\n",
        "  print(Z.shape)\n",
        "\n",
        "  L = (1/2) * ((Z - y_train) ** 2).mean()\n",
        "  print(L.shape)\n",
        "  print(L)\n",
        "  W.retain_grad()\n",
        "  b.retain_grad()\n",
        "  L.backward()\n",
        "\n",
        "print(W.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkLuNFBdDqkK",
        "outputId": "9a54a77b-22e7-4f4e-ae93-4842c38b97c5"
      },
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([436, 1])\n",
            "torch.Size([])\n",
            "tensor(101.7790, grad_fn=<MulBackward0>)\n",
            "tensor([[ -43.6468],\n",
            "        [ -19.2796],\n",
            "        [ -27.1753],\n",
            "        [ -11.3674],\n",
            "        [ -15.0596],\n",
            "        [-121.8095],\n",
            "        [-373.0967],\n",
            "        [-165.0795],\n",
            "        [ -61.0370],\n",
            "        [ -32.0596],\n",
            "        [ -62.9264]])\n",
            "tensor([-14.2643])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Everything here is now converted into `TensorValue` class"
      ],
      "metadata": {
        "id": "jqlmx5Vskol4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = TensorValue(X_train, label = 'x_train')\n",
        "y_train = TensorValue(y_train, label = 'y_train')\n",
        "\n",
        "W = torch.randn((11,1), dtype = torch.float32, requires_grad = True) * 0.01\n",
        "b = torch.tensor([1.], requires_grad = True)\n",
        "print(b)\n",
        "print(b.shape)\n",
        "\n",
        "W = TensorValue(W, label = 'w')\n",
        "b = TensorValue(b, label = 'b')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9w1enFs7ZrV",
        "outputId": "2d3d5823-d116-44bd-e6d7-d8ff34d1baf9"
      },
      "execution_count": 335,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.], requires_grad=True)\n",
            "torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entire backpropagation done using the auto differentiation based `TensorValue` class"
      ],
      "metadata": {
        "id": "PsNwwjT0kvE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "lr = 0.001\n",
        "print(\"y_train shape ::\", y_train.shape)\n",
        "\n",
        "for i in range(epochs):\n",
        "  T = X_train @ W\n",
        "  T.label = \"T\"\n",
        "  Z = T + b\n",
        "  Z.label = \"Z\"\n",
        "  print(Z.shape)\n",
        "\n",
        "  diff = Z - y_train\n",
        "  diff.label = \"diff\"\n",
        "  diff_2 = diff ** 2\n",
        "  diff_2.label = \"diff_2\"\n",
        "  diff_2_mean = diff_2.mean()\n",
        "  diff_2_mean.label = \"diff_2_mean\"\n",
        "  L1 = (1/2) * diff_2_mean\n",
        "  L1.label = \"Loss\"\n",
        "\n",
        "  print('------------------------------------------------')\n",
        "  print(\"Z shape ::\", Z.shape)\n",
        "  print(\"Y_train shape ::\", y_train.shape)\n",
        "  print(\"Diff shape :: \",diff.shape)\n",
        "  print(\"Mean shape :: \", diff_2_mean.shape)\n",
        "  print(\"Loss value :: \",L)\n",
        "  print('------------------------------------------------')\n",
        "\n",
        "  diff_2_mean.tensor.retain_grad()\n",
        "  diff_2.tensor.retain_grad()\n",
        "  diff.tensor.retain_grad()\n",
        "  Z.tensor.retain_grad()\n",
        "  T.tensor.retain_grad()\n",
        "  W.tensor.retain_grad()\n",
        "  b.tensor.retain_grad()\n",
        "\n",
        "  L1.backward()\n",
        "\n",
        "print(\"The shape of loss's gradient\")\n",
        "print(L1.grad.shape)\n",
        "print(\"---------------------------------------\")\n",
        "print(\"W's grad\")\n",
        "print(W.grad)\n",
        "print(\"---------------------------------------\")\n",
        "print(\"b's grad\")\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwQNk2CJ76wl",
        "outputId": "1dbd0a69-aa01-4321-8ad0-797e38479558"
      },
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train shape :: torch.Size([436, 1])\n",
            "torch.Size([436, 1])\n",
            "------------------------------------------------\n",
            "Z shape :: torch.Size([436, 1])\n",
            "Y_train shape :: torch.Size([436, 1])\n",
            "Diff shape ::  torch.Size([436, 1])\n",
            "Mean shape ::  torch.Size([])\n",
            "Loss value ::  tensor(101.7790, grad_fn=<MulBackward0>)\n",
            "------------------------------------------------\n",
            "The shape of loss's gradient\n",
            "torch.Size([])\n",
            "---------------------------------------\n",
            "W's grad\n",
            "tensor([[ -44.7586],\n",
            "        [ -19.7416],\n",
            "        [ -27.8562],\n",
            "        [ -11.6519],\n",
            "        [ -15.4134],\n",
            "        [-124.7164],\n",
            "        [-382.6177],\n",
            "        [-169.0456],\n",
            "        [ -62.5972],\n",
            "        [ -32.8447],\n",
            "        [ -64.5003]], grad_fn=<AddBackward0>)\n",
            "---------------------------------------\n",
            "b's grad\n",
            "tensor([-14.6040], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the computational graph"
      ],
      "metadata": {
        "id": "ORQ8TaFRgN8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "draw_dot(L1)\n"
      ],
      "metadata": {
        "id": "T3B-d5rJ9ayU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "56ea4ab6-ceba-4e15-bb03-929e85c6d58f"
      },
      "execution_count": 338,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"4186pt\" height=\"128pt\"\n viewBox=\"0.00 0.00 4185.88 128.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 124)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-124 4181.88,-124 4181.88,4 -4,4\"/>\n<!-- 132065999511056 -->\n<g id=\"node1\" class=\"node\">\n<title>132065999511056</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"2476.78,-27.5 2476.78,-63.5 2822.78,-63.5 2822.78,-27.5 2476.78,-27.5\"/>\n<text text-anchor=\"middle\" x=\"2494.78\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">diff</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2512.78,-27.5 2512.78,-63.5 \"/>\n<text text-anchor=\"middle\" x=\"2591.78\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">shape torch.Size([436, 1])</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2670.78,-27.5 2670.78,-63.5 \"/>\n<text text-anchor=\"middle\" x=\"2746.78\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad torch.Size([436, 1])</text>\n</g>\n<!-- 132065999507152** -->\n<g id=\"node10\" class=\"node\">\n<title>132065999507152**</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"2885.78\" cy=\"-45.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"2885.78\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">**</text>\n</g>\n<!-- 132065999511056&#45;&gt;132065999507152** -->\n<g id=\"edge12\" class=\"edge\">\n<title>132065999511056&#45;&gt;132065999507152**</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2823,-45.5C2832.16,-45.5 2840.74,-45.5 2848.42,-45.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2848.64,-49 2858.64,-45.5 2848.64,-42 2848.64,-49\"/>\n</g>\n<!-- 132065999511056&#45; -->\n<g id=\"node2\" class=\"node\">\n<title>132065999511056&#45;</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"2413.78\" cy=\"-45.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"2413.78\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45;</text>\n</g>\n<!-- 132065999511056&#45;&#45;&gt;132065999511056 -->\n<g id=\"edge1\" class=\"edge\">\n<title>132065999511056&#45;&#45;&gt;132065999511056</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2441.17,-45.5C2448.54,-45.5 2457.13,-45.5 2466.56,-45.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2466.67,-49 2476.67,-45.5 2466.67,-42 2466.67,-49\"/>\n</g>\n<!-- 132065999517776 -->\n<g id=\"node3\" class=\"node\">\n<title>132065999517776</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"3894.88,-27.5 3894.88,-63.5 4177.88,-63.5 4177.88,-27.5 3894.88,-27.5\"/>\n<text text-anchor=\"middle\" x=\"3915.88\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">Loss</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"3936.88,-27.5 3936.88,-63.5 \"/>\n<text text-anchor=\"middle\" x=\"3998.88\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">shape torch.Size([])</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"4060.88,-27.5 4060.88,-63.5 \"/>\n<text text-anchor=\"middle\" x=\"4119.38\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad torch.Size([])</text>\n</g>\n<!-- 132065999517776* -->\n<g id=\"node4\" class=\"node\">\n<title>132065999517776*</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"3831.88\" cy=\"-45.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"3831.88\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n</g>\n<!-- 132065999517776*&#45;&gt;132065999517776 -->\n<g id=\"edge2\" class=\"edge\">\n<title>132065999517776*&#45;&gt;132065999517776</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3858.94,-45.5C3866.39,-45.5 3875.09,-45.5 3884.55,-45.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3884.67,-49 3894.67,-45.5 3884.67,-42 3884.67,-49\"/>\n</g>\n<!-- 132066149942864 -->\n<g id=\"node5\" class=\"node\">\n<title>132066149942864</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"27.5,-56.5 27.5,-92.5 350.5,-92.5 350.5,-56.5 27.5,-56.5\"/>\n<text text-anchor=\"middle\" x=\"40.5\" y=\"-70.8\" font-family=\"Times,serif\" font-size=\"14.00\">w</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"53.5,-56.5 53.5,-92.5 \"/>\n<text text-anchor=\"middle\" x=\"129.5\" y=\"-70.8\" font-family=\"Times,serif\" font-size=\"14.00\">shape torch.Size([11, 1])</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"205.5,-56.5 205.5,-92.5 \"/>\n<text text-anchor=\"middle\" x=\"278\" y=\"-70.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad torch.Size([11, 1])</text>\n</g>\n<!-- 132065999885776@ -->\n<g id=\"node23\" class=\"node\">\n<title>132065999885776@</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"441\" cy=\"-46.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"441\" y=\"-42.8\" font-family=\"Times,serif\" font-size=\"14.00\">@</text>\n</g>\n<!-- 132066149942864&#45;&gt;132065999885776@ -->\n<g id=\"edge13\" class=\"edge\">\n<title>132066149942864&#45;&gt;132065999885776@</title>\n<path fill=\"none\" stroke=\"black\" d=\"M350.8,-56.49C370.48,-54.29 388.87,-52.23 403.77,-50.56\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"404.43,-54.01 413.98,-49.41 403.65,-47.05 404.43,-54.01\"/>\n</g>\n<!-- 132065999514064 -->\n<g id=\"node6\" class=\"node\">\n<title>132065999514064</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1000.39,-83.5 1000.39,-119.5 1333.39,-119.5 1333.39,-83.5 1000.39,-83.5\"/>\n<text text-anchor=\"middle\" x=\"1011.89\" y=\"-97.8\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1023.39,-83.5 1023.39,-119.5 \"/>\n<text text-anchor=\"middle\" x=\"1102.39\" y=\"-97.8\" font-family=\"Times,serif\" font-size=\"14.00\">shape torch.Size([436, 1])</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1181.39,-83.5 1181.39,-119.5 \"/>\n<text text-anchor=\"middle\" x=\"1257.39\" y=\"-97.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad torch.Size([436, 1])</text>\n</g>\n<!-- 132065999516880+ -->\n<g id=\"node12\" class=\"node\">\n<title>132065999516880+</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1397.39\" cy=\"-73.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1397.39\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n</g>\n<!-- 132065999514064&#45;&gt;132065999516880+ -->\n<g id=\"edge14\" class=\"edge\">\n<title>132065999514064&#45;&gt;132065999516880+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1314.87,-83.49C1331.52,-81.45 1347.15,-79.53 1360.19,-77.94\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1361,-81.36 1370.5,-76.67 1360.15,-74.42 1361,-81.36\"/>\n</g>\n<!-- 132065999514064broadcast -->\n<g id=\"node7\" class=\"node\">\n<title>132065999514064broadcast</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"919.2\" cy=\"-101.5\" rx=\"44.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"919.2\" y=\"-97.8\" font-family=\"Times,serif\" font-size=\"14.00\">broadcast</text>\n</g>\n<!-- 132065999514064broadcast&#45;&gt;132065999514064 -->\n<g id=\"edge3\" class=\"edge\">\n<title>132065999514064broadcast&#45;&gt;132065999514064</title>\n<path fill=\"none\" stroke=\"black\" d=\"M963.56,-101.5C971.74,-101.5 980.74,-101.5 990.27,-101.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"990.37,-105 1000.37,-101.5 990.37,-98 990.37,-105\"/>\n</g>\n<!-- 132065999885456 -->\n<g id=\"node8\" class=\"node\">\n<title>132065999885456</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"0,-1.5 0,-37.5 378,-37.5 378,-1.5 0,-1.5\"/>\n<text text-anchor=\"middle\" x=\"27.5\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">x_train</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"55,-1.5 55,-37.5 \"/>\n<text text-anchor=\"middle\" x=\"137.5\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">shape torch.Size([436, 11])</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"220,-1.5 220,-37.5 \"/>\n<text text-anchor=\"middle\" x=\"299\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad torch.Size([436, 11])</text>\n</g>\n<!-- 132065999885456&#45;&gt;132065999885776@ -->\n<g id=\"edge23\" class=\"edge\">\n<title>132065999885456&#45;&gt;132065999885776@</title>\n<path fill=\"none\" stroke=\"black\" d=\"M356.75,-37.51C374.28,-39.4 390.57,-41.16 404.01,-42.61\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"403.83,-46.11 414.14,-43.71 404.58,-39.15 403.83,-46.11\"/>\n</g>\n<!-- 132065999507152 -->\n<g id=\"node9\" class=\"node\">\n<title>132065999507152</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"2948.78,-27.5 2948.78,-63.5 3308.78,-63.5 3308.78,-27.5 2948.78,-27.5\"/>\n<text text-anchor=\"middle\" x=\"2973.78\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">diff_2</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2998.78,-27.5 2998.78,-63.5 \"/>\n<text text-anchor=\"middle\" x=\"3077.78\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">shape torch.Size([436, 1])</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"3156.78,-27.5 3156.78,-63.5 \"/>\n<text text-anchor=\"middle\" x=\"3232.78\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad torch.Size([436, 1])</text>\n</g>\n<!-- 132065999511888mean -->\n<g id=\"node19\" class=\"node\">\n<title>132065999511888mean</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"3375.33\" cy=\"-45.5\" rx=\"30.59\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"3375.33\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">mean</text>\n</g>\n<!-- 132065999507152&#45;&gt;132065999511888mean -->\n<g id=\"edge21\" class=\"edge\">\n<title>132065999507152&#45;&gt;132065999511888mean</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3308.8,-45.5C3318.01,-45.5 3326.67,-45.5 3334.49,-45.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3334.61,-49 3344.61,-45.5 3334.61,-42 3334.61,-49\"/>\n</g>\n<!-- 132065999507152**&#45;&gt;132065999507152 -->\n<g id=\"edge4\" class=\"edge\">\n<title>132065999507152**&#45;&gt;132065999507152</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2913.03,-45.5C2920.37,-45.5 2928.94,-45.5 2938.36,-45.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2938.47,-49 2948.47,-45.5 2938.47,-42 2938.47,-49\"/>\n</g>\n<!-- 132065999516880 -->\n<g id=\"node11\" class=\"node\">\n<title>132065999516880</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1475.39,-55.5 1475.39,-91.5 1810.39,-91.5 1810.39,-55.5 1475.39,-55.5\"/>\n<text text-anchor=\"middle\" x=\"1487.89\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">Z</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1500.39,-55.5 1500.39,-91.5 \"/>\n<text text-anchor=\"middle\" x=\"1579.39\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">shape torch.Size([436, 1])</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1658.39,-55.5 1658.39,-91.5 \"/>\n<text text-anchor=\"middle\" x=\"1734.39\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad torch.Size([436, 1])</text>\n</g>\n<!-- 132065999519504broadcast -->\n<g id=\"node15\" class=\"node\">\n<title>132065999519504broadcast</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1905.59\" cy=\"-73.5\" rx=\"44.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1905.59\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">broadcast</text>\n</g>\n<!-- 132065999516880&#45;&gt;132065999519504broadcast -->\n<g id=\"edge19\" class=\"edge\">\n<title>132065999516880&#45;&gt;132065999519504broadcast</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1810.47,-73.5C1824.97,-73.5 1838.82,-73.5 1851.22,-73.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1851.28,-77 1861.28,-73.5 1851.28,-70 1851.28,-77\"/>\n</g>\n<!-- 132065999516880+&#45;&gt;132065999516880 -->\n<g id=\"edge5\" class=\"edge\">\n<title>132065999516880+&#45;&gt;132065999516880</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1424.45,-73.5C1435.52,-73.5 1449.44,-73.5 1464.87,-73.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1465.21,-77 1475.21,-73.5 1465.21,-70 1465.21,-77\"/>\n</g>\n<!-- 132065999884496 -->\n<g id=\"node13\" class=\"node\">\n<title>132065999884496</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1460.39,-0.5 1460.39,-36.5 1825.39,-36.5 1825.39,-0.5 1460.39,-0.5\"/>\n<text text-anchor=\"middle\" x=\"1487.89\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">y_train</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1515.39,-0.5 1515.39,-36.5 \"/>\n<text text-anchor=\"middle\" x=\"1594.39\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">shape torch.Size([436, 1])</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1673.39,-0.5 1673.39,-36.5 \"/>\n<text text-anchor=\"middle\" x=\"1749.39\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad torch.Size([436, 1])</text>\n</g>\n<!-- 132065999509840broadcast -->\n<g id=\"node21\" class=\"node\">\n<title>132065999509840broadcast</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1905.59\" cy=\"-18.5\" rx=\"44.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1905.59\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">broadcast</text>\n</g>\n<!-- 132065999884496&#45;&gt;132065999509840broadcast -->\n<g id=\"edge15\" class=\"edge\">\n<title>132065999884496&#45;&gt;132065999509840broadcast</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1825.66,-18.5C1834.54,-18.5 1843.03,-18.5 1850.94,-18.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1850.99,-22 1860.99,-18.5 1850.99,-15 1850.99,-22\"/>\n</g>\n<!-- 132065999519504 -->\n<g id=\"node14\" class=\"node\">\n<title>132065999519504</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"2000.78,-55.5 2000.78,-91.5 2335.78,-91.5 2335.78,-55.5 2000.78,-55.5\"/>\n<text text-anchor=\"middle\" x=\"2013.28\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">Z</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2025.78,-55.5 2025.78,-91.5 \"/>\n<text text-anchor=\"middle\" x=\"2104.78\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">shape torch.Size([436, 1])</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2183.78,-55.5 2183.78,-91.5 \"/>\n<text text-anchor=\"middle\" x=\"2259.78\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad torch.Size([436, 1])</text>\n</g>\n<!-- 132065999519504&#45;&gt;132065999511056&#45; -->\n<g id=\"edge22\" class=\"edge\">\n<title>132065999519504&#45;&gt;132065999511056&#45;</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2325.91,-55.49C2344.74,-53.32 2362.36,-51.3 2376.74,-49.64\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2377.54,-53.08 2387.07,-48.46 2376.74,-46.12 2377.54,-53.08\"/>\n</g>\n<!-- 132065999519504broadcast&#45;&gt;132065999519504 -->\n<g id=\"edge6\" class=\"edge\">\n<title>132065999519504broadcast&#45;&gt;132065999519504</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1949.93,-73.5C1961.93,-73.5 1975.74,-73.5 1990.46,-73.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1990.78,-77 2000.78,-73.5 1990.78,-70 1990.78,-77\"/>\n</g>\n<!-- 132065999891216 -->\n<g id=\"node16\" class=\"node\">\n<title>132065999891216</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"999.39,-28.5 999.39,-64.5 1334.39,-64.5 1334.39,-28.5 999.39,-28.5\"/>\n<text text-anchor=\"middle\" x=\"1011.89\" y=\"-42.8\" font-family=\"Times,serif\" font-size=\"14.00\">T</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1024.39,-28.5 1024.39,-64.5 \"/>\n<text text-anchor=\"middle\" x=\"1103.39\" y=\"-42.8\" font-family=\"Times,serif\" font-size=\"14.00\">shape torch.Size([436, 1])</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1182.39,-28.5 1182.39,-64.5 \"/>\n<text text-anchor=\"middle\" x=\"1258.39\" y=\"-42.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad torch.Size([436, 1])</text>\n</g>\n<!-- 132065999891216&#45;&gt;132065999516880+ -->\n<g id=\"edge18\" class=\"edge\">\n<title>132065999891216&#45;&gt;132065999516880+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1320.3,-64.51C1335.1,-66.26 1348.92,-67.89 1360.63,-69.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1360.4,-72.77 1370.74,-70.47 1361.22,-65.82 1360.4,-72.77\"/>\n</g>\n<!-- 132065999891216broadcast -->\n<g id=\"node17\" class=\"node\">\n<title>132065999891216broadcast</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"919.2\" cy=\"-46.5\" rx=\"44.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"919.2\" y=\"-42.8\" font-family=\"Times,serif\" font-size=\"14.00\">broadcast</text>\n</g>\n<!-- 132065999891216broadcast&#45;&gt;132065999891216 -->\n<g id=\"edge7\" class=\"edge\">\n<title>132065999891216broadcast&#45;&gt;132065999891216</title>\n<path fill=\"none\" stroke=\"black\" d=\"M963.56,-46.5C971.45,-46.5 980.11,-46.5 989.26,-46.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"989.38,-50 999.38,-46.5 989.38,-43 989.38,-50\"/>\n</g>\n<!-- 132065999511888 -->\n<g id=\"node18\" class=\"node\">\n<title>132065999511888</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"3441.88,-27.5 3441.88,-63.5 3768.88,-63.5 3768.88,-27.5 3441.88,-27.5\"/>\n<text text-anchor=\"middle\" x=\"3484.88\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">diff_2_mean</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"3527.88,-27.5 3527.88,-63.5 \"/>\n<text text-anchor=\"middle\" x=\"3589.88\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">shape torch.Size([])</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"3651.88,-27.5 3651.88,-63.5 \"/>\n<text text-anchor=\"middle\" x=\"3710.38\" y=\"-41.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad torch.Size([])</text>\n</g>\n<!-- 132065999511888&#45;&gt;132065999517776* -->\n<g id=\"edge17\" class=\"edge\">\n<title>132065999511888&#45;&gt;132065999517776*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3768.94,-45.5C3778.07,-45.5 3786.65,-45.5 3794.34,-45.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3794.58,-49 3804.58,-45.5 3794.58,-42 3794.58,-49\"/>\n</g>\n<!-- 132065999511888mean&#45;&gt;132065999511888 -->\n<g id=\"edge8\" class=\"edge\">\n<title>132065999511888mean&#45;&gt;132065999511888</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3406.14,-45.5C3413.59,-45.5 3422.12,-45.5 3431.37,-45.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3431.66,-49 3441.66,-45.5 3431.66,-42 3431.66,-49\"/>\n</g>\n<!-- 132065999509840 -->\n<g id=\"node20\" class=\"node\">\n<title>132065999509840</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1985.78,-0.5 1985.78,-36.5 2350.78,-36.5 2350.78,-0.5 1985.78,-0.5\"/>\n<text text-anchor=\"middle\" x=\"2013.28\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">y_train</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2040.78,-0.5 2040.78,-36.5 \"/>\n<text text-anchor=\"middle\" x=\"2119.78\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">shape torch.Size([436, 1])</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2198.78,-0.5 2198.78,-36.5 \"/>\n<text text-anchor=\"middle\" x=\"2274.78\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad torch.Size([436, 1])</text>\n</g>\n<!-- 132065999509840&#45;&gt;132065999511056&#45; -->\n<g id=\"edge20\" class=\"edge\">\n<title>132065999509840&#45;&gt;132065999511056&#45;</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2331.7,-36.51C2348.33,-38.35 2363.82,-40.07 2376.71,-41.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2376.57,-45.01 2386.89,-42.63 2377.34,-38.05 2376.57,-45.01\"/>\n</g>\n<!-- 132065999509840broadcast&#45;&gt;132065999509840 -->\n<g id=\"edge9\" class=\"edge\">\n<title>132065999509840broadcast&#45;&gt;132065999509840</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1949.93,-18.5C1957.8,-18.5 1966.44,-18.5 1975.62,-18.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1975.76,-22 1985.76,-18.5 1975.76,-15 1975.76,-22\"/>\n</g>\n<!-- 132065999885776 -->\n<g id=\"node22\" class=\"node\">\n<title>132065999885776</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"504,-28.5 504,-64.5 839,-64.5 839,-28.5 504,-28.5\"/>\n<text text-anchor=\"middle\" x=\"516.5\" y=\"-42.8\" font-family=\"Times,serif\" font-size=\"14.00\">T</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"529,-28.5 529,-64.5 \"/>\n<text text-anchor=\"middle\" x=\"608\" y=\"-42.8\" font-family=\"Times,serif\" font-size=\"14.00\">shape torch.Size([436, 1])</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"687,-28.5 687,-64.5 \"/>\n<text text-anchor=\"middle\" x=\"763\" y=\"-42.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad torch.Size([436, 1])</text>\n</g>\n<!-- 132065999885776&#45;&gt;132065999891216broadcast -->\n<g id=\"edge16\" class=\"edge\">\n<title>132065999885776&#45;&gt;132065999891216broadcast</title>\n<path fill=\"none\" stroke=\"black\" d=\"M839.1,-46.5C848.03,-46.5 856.6,-46.5 864.59,-46.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"864.74,-50 874.74,-46.5 864.74,-43 864.74,-50\"/>\n</g>\n<!-- 132065999885776@&#45;&gt;132065999885776 -->\n<g id=\"edge10\" class=\"edge\">\n<title>132065999885776@&#45;&gt;132065999885776</title>\n<path fill=\"none\" stroke=\"black\" d=\"M468.21,-46.5C475.61,-46.5 484.25,-46.5 493.72,-46.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"493.88,-50 503.88,-46.5 493.88,-43 493.88,-50\"/>\n</g>\n<!-- 132066021414864 -->\n<g id=\"node24\" class=\"node\">\n<title>132066021414864</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"532.5,-83.5 532.5,-119.5 810.5,-119.5 810.5,-83.5 532.5,-83.5\"/>\n<text text-anchor=\"middle\" x=\"544\" y=\"-97.8\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"555.5,-83.5 555.5,-119.5 \"/>\n<text text-anchor=\"middle\" x=\"621\" y=\"-97.8\" font-family=\"Times,serif\" font-size=\"14.00\">shape torch.Size([1])</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"686.5,-83.5 686.5,-119.5 \"/>\n<text text-anchor=\"middle\" x=\"748.5\" y=\"-97.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad torch.Size([1])</text>\n</g>\n<!-- 132066021414864&#45;&gt;132065999514064broadcast -->\n<g id=\"edge11\" class=\"edge\">\n<title>132066021414864&#45;&gt;132065999514064broadcast</title>\n<path fill=\"none\" stroke=\"black\" d=\"M810.79,-101.5C829.85,-101.5 848.42,-101.5 864.6,-101.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"864.87,-105 874.87,-101.5 864.87,-98 864.87,-105\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x781d043d0890>"
            ]
          },
          "metadata": {},
          "execution_count": 338
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6vQ8YTcsmliy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}